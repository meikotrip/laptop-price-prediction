# -*- coding: utf-8 -*-
"""Laptop_Price_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tFwGM4gUv6Ixg4LONUosimoEn-qAUJEr

# Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
# Mengimport library-library yang akan digunakan
import gdown
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""# Load Dataset"""

# Proses load data
url = "https://drive.google.com/uc?export=download&id=1aghEPd2qZk0gqQERg8PLai4pjcr2es3J"
output = 'laptop.csv'

gdown.download(url, output, quiet=False)

# Membaca data
laptop_df = pd.read_csv('laptop.csv')
laptop_df.head()

"""# Exploratory Data Analysis (EDA)"""

# Melihat informasi pada data
laptop_df.info()

# Melihat deskripsi statistik pada data
laptop_df.describe()

"""Dari info dan deskripsi statistik diatas, ada beberapa hal yang dapat digaris bawahi yaitu :
- Ada beberapa kolom yang tidak diperlukan dalam analisis data seperti kolom 'Unnamed:0.1' dan 'Unnamed:0'
- Nilai pada kolom 'spec_rating' bisa lebih disederhanakan agar mudah dibaca
- Nilai dan tipe data pada kolom 'Ram', 'ROM' dapat diubah menjadi numerik
- Terlihat data anomali (_outlier_) dimana data harga maksimalnya 5 kali lipat dari harga pada Q3 (75%)
"""

# Dari data laptop berikut terdapat 2 kolom yang tidak diperlukan yaitu 'Unnamed:0.1' dan 'Unnamed: 0'
# maka dari itu data berikut dapat di drop

laptop_df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)
laptop_df.head()

# Nilai pada kolom 'spec_rating' disederhanakan dengan mengubah semua nilai jadi hanya 2 angka dibelakang koma
laptop_df['spec_rating'] = laptop_df['spec_rating'].apply(lambda x: round(x, 2))

# Nilai dan tipe data pada kolom 'Ram', 'ROM' diubah menjadi numerik
laptop_df['Ram'] = laptop_df['Ram'].str.replace('GB', '').astype(int)
laptop_df['ROM'] = laptop_df['ROM'].str.replace('GB', '').str.replace('TB', '000').astype(int)

laptop_df.head()

# Menangani Outliers

# Melakukan visualisasi pada kolom harga menggunakan boxplot
sns.boxplot(x=laptop_df['price'])

# Mengatasi outlier pada data menggunakan IQR Method
Q1 = laptop_df['price'].quantile(0.25)
Q3 = laptop_df['price'].quantile(0.75)

IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

laptop_df = laptop_df[(laptop_df['price'] >= lower_bound) & (laptop_df['price'] <= upper_bound)]

laptop_df.shape

"""## Univariate Analysis"""

# membagi features menjadi categorical dan numerical
categorical_features = ['brand','processor','CPU','Ram_type','ROM_type','GPU','OS']
numerical_features = ['price','spec_rating','Ram','ROM','display_size','resolution_width','resolution_height','warranty']

"""### Categorical features"""

# Fitur brand
brand = categorical_features[0]
count = laptop_df[brand].value_counts()
percent = 100 * laptop_df[brand].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Melakukan plot terhadap jumlah laptop setiap brand
count.plot(kind='barh', title='Jumlah setiap jenis brand Laptop', color='maroon')
plt.xlabel('Jumlah Laptop')
plt.ylabel('Brand')

# Fitur processor
processor = categorical_features[1]
count = laptop_df[processor].value_counts()
percent = 100 * laptop_df[processor].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Fitur CPU
cpu = categorical_features[2]
count = laptop_df[cpu].value_counts()
percent = 100 * laptop_df[cpu].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Melakukan plot terhadap jumlah laptop setiap CPU
count.plot(kind='barh', title='Jumlah setiap jenis CPU Laptop', color='maroon')
plt.xlabel('Jumlah Laptop')
plt.ylabel('CPU')

# Fitur Ram_type
Ram_type = categorical_features[3]
count = laptop_df[Ram_type].value_counts()
percent = 100 * laptop_df[Ram_type].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Melakukan plot terhadap jumlah laptop setiap Ram_type
count.plot(kind='barh', title='Jumlah setiap jenis Ram_type Laptop', color='maroon')
plt.xlabel('Jumlah Laptop')
plt.ylabel('Ram_type')

# Fitur Rom_type
Rom_type = categorical_features[4]
count = laptop_df[Rom_type].value_counts()
percent = 100 * laptop_df[Rom_type].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Melakukan plot terhadap jumlah laptop setiap Rom_type
count.plot(kind='barh', title='Jumlah setiap jenis Rom_type Laptop', color='maroon')
plt.xlabel('Jumlah Laptop')
plt.ylabel('Rom_type')

# Fitur GPU
GPU = categorical_features[5]
count = laptop_df[GPU].value_counts()
percent = 100 * laptop_df[GPU].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Fitur OS
os = categorical_features[6]
count = laptop_df[os].value_counts()
percent = 100 * laptop_df[os].value_counts(normalize=True)

# memasukkan data ke data frame
df = pd.DataFrame({'jumlah sample': count, 'persentase': percent.round(1)})
print(df)

# Melakukan plot terhadap jumlah laptop setiap OS
count.plot(kind='barh', title='Jumlah setiap jenis OS Laptop', color='maroon')
plt.xlabel('Jumlah Laptop')
plt.ylabel('OS')

"""Dari beberapa barplot kolom-kolom kategori diatas, diperoleh :
- Terdapat 29 kategori brand dengan brand terbanyak yaitu HP sebanyak 170 laptop
- Terdapat 165 kategori processor dengan processor terbanyak yaitu 12th Gen Intel Core i5 1235U sebanyak 49 laptop
- Terdapat 24 kategori CPU dengan CPU terbanyak yaitu Quad Core, 8 Threads sebanyak 130 laptop
- Terdapat 12 kategori tipe RAM dengan tipe RAM terbanyak yaitu DDR4 sebanyak 497 laptop
- Terdapat 2 kategori tipe ROM dengen tipe ROM terbanyak yaitu SSD sebanyak 801 laptop
- Terdapat 115 kategori GPU dengan GPU terbanyak yaitu Intel Iris Xe Graphics sebanyak 98 laptop
- Terdapat 12 kategori OS dengan OS terbanyak yaitu Windows 11 OS sebanyak 723 laptop

### Numerical features
"""

laptop_df.hist(bins=50, figsize=(20,15))
plt.show()

"""dari histogram di atas, khususnya histogram untuk variabel "price" yang merupakan fitur target (label) pada data, dapat diperoleh beberapa informasi, antara lain:

- Rentang harga laptop cukup tinggi yaitu dari skala 10000 hingga sekitar 160000.
- Harga laptop lebih banyak berada di sekitar kurang dari 100000.
- Distribusi harga miring ke kanan (right-skewed).

## Multivariate Analysis

### Categorical features
"""

cat_features = ['brand','CPU','Ram_type','ROM_type','OS']

for col in cat_features:
    # Menghitung rata-rata harga untuk setiap kategori dalam kolom
    avg_price = laptop_df.groupby(col)['price'].mean()

    # Membuat bar plot
    plt.figure(figsize=(12, 6))  # Ukuran plot
    plt.barh(avg_price.index,avg_price.values, color='maroon')

    # Menambahkan judul dan label
    plt.title(f"Rata-rata 'price' Relatif terhadap {col}")
    plt.xlabel('Rata-rata Price')
    plt.ylabel(col)

    # Menampilkan plot
    plt.show()

"""Dari beberapa barplot rata-rata 'price' relatif terhadap fitur-fitur kategori di atas,  insight yang dapat diperoleh yaitu sebagai berikut:

- Beberapa fitur seperti 'brand', 'processor', 'CPU', 'Ram_type', 'GPU','OS' terlalu banyak kategori brand membuat beberapa kategori yang jarang muncul seperti contoh pada kolom brand yaitu Ninkear, Primebook, Vaio, Avita, iBall, Walker menyebabkan data menjadi sparse dan akan menyulitkan dalam memprediksi harga laptop.
- Pada fitur ‘ROM_type’, laptop dengan tipe ROM SSD memiliki rerata yang paling tinggi daripada Hard-Disk. Dari sini dapat disimpulkan bahwa tipe ROM memiliki pengaruh yang tinggi terhadap harga.
- Kesimpulan akhir, fitur tipe ROM memiliki pengaruh tinggi terhadap harga selain itu dapat menghindari dimensionality curse dan data sparse sehingga akan digunakan untuk prediksi harga.

### Numerical features
"""

# Untuk mengamati hubungan antara fitur numerik, kita akan menggunakan fungsi pairplot().
sns.pairplot(laptop_df, diag_kind='kde')

# evaluasi skor korelasi fitur lain terhadap price
plt.figure(figsize=(10,8))
correlation_matrix = laptop_df[numerical_features].corr().round(2)

# untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk untuk fitur numerik", size=20)

"""Pada pola sebaran data pada pairplot dan correlation matrix diatas, dapat disimpulkan bahwa fitur-fitur seperti 'spec_rating', 'Ram', 'ROM', 'resolution_width','resolution_height' memiliki korelasi positif terhadap fitur 'price'. Sementara itu, fitur 'display_size' dan 'warranty' tidak terlalu berkorelasi sehingga fitur tersebut dapat di-drop bersamaan dengan beberapa fitur kategorikal sebelumnya"""

# Melakukan drop beberapa kolom yang tidak digunakan untuk model prediksi
laptop_clean_df = laptop_df.drop(['name','brand', 'processor', 'CPU', 'Ram_type', 'GPU', 'OS','display_size','warranty'], axis=1)
laptop_clean_df.head()

"""# Data Preparation

## Encoding fitur kategori menggunakan OneHotEncoder
"""

# Melakukan encoding pada kolom kategorikal
from sklearn.preprocessing import OneHotEncoder
laptop_clean_df = pd.concat([laptop_clean_df, pd.get_dummies(laptop_clean_df['ROM_type'], prefix='ROM_type',dtype='int64')], axis=1)

laptop_clean_df.drop(['ROM_type'], axis=1, inplace=True)
laptop_clean_df.head()

"""### Split Dataset"""

# Membagi dataset menjadi dua bagian train dan test
from sklearn.model_selection import train_test_split

X = laptop_clean_df.drop(['price'], axis=1)
Y = laptop_clean_df['price']

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.125, random_state=64)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standarisasi"""

# Melakukan proses scaling dengan standarisasi nilai
from sklearn.preprocessing import StandardScaler

numerical_features = ['spec_rating','Ram','ROM','resolution_width','resolution_height']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])

X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])

X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""# Model Development"""

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

# siapkan data frame untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse','train_r2','test_r2'],
                      columns=['KNN', 'RandomForest', 'LinearRegression', 'DecisionTree'])

# Membangun model prediksi dengan algoritma KNN
from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=6)
knn.fit(X_train, y_train)

models.loc['train_mse','KNN'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)
models.loc['train_r2','KNN'] = r2_score(y_pred = knn.predict(X_train), y_true=y_train)

# Membangun model prediksi dengan algoritma RandomForest
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100, max_depth=32, random_state=64, n_jobs=1)
rf.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred = rf.predict(X_train), y_true=y_train)
models.loc['train_r2','RandomForest'] = r2_score(y_pred = rf.predict(X_train), y_true=y_train)

# Membangun model prediksi dengan algoritma Linear Regression
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(X_train, y_train)

models.loc['train_mse','LinearRegression'] = mean_squared_error(y_pred = lr.predict(X_train), y_true=y_train)
models.loc['train_r2','LinearRegression'] = r2_score(y_pred = lr.predict(X_train), y_true=y_train)

# Membangun model prediksi dengan algoritma DecisionTree
from sklearn.tree import DecisionTreeRegressor

dt = DecisionTreeRegressor(max_depth=32, random_state=64)
dt.fit(X_train, y_train)

models.loc['train_mse','DecisionTree'] = mean_squared_error(y_pred = dt.predict(X_train), y_true=y_train)
models.loc['train_r2','DecisionTree'] = r2_score(y_pred = dt.predict(X_train), y_true=y_train)

"""# Evaluasi Model"""

#Scaling data test dengan standarisasi nilai
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Buat variabel mse yang isinya adalah dataframe nilai mse,r2_score data train dan test pada masing-masing algoritma
metrics_eval = pd.DataFrame(columns=['train_mse', 'test_mse','train_r2','test_r2'], index=['KNN','RF','LR','DT'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': rf, 'LR': lr, 'DT': dt}

# Hitung Mean Squared Error dan R2_score masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    metrics_eval.loc[name, 'train_mse'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e6
    metrics_eval.loc[name, 'test_mse'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e6
    metrics_eval.loc[name, 'train_r2'] = r2_score(y_true=y_train, y_pred=model.predict(X_train))
    metrics_eval.loc[name, 'test_r2'] = r2_score(y_true=y_test, y_pred=model.predict(X_test))

# Panggil mse
metrics_eval

# Melihat hasil prediksi dari data test
prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Dari hasil prediksi dan hasil evaluasi model dengan melihat metriks-metriks yang digunakan didapatkan bahwa algoritma dengan hasil prediksi yang paling mendekati yaitu algoritma <b>Random Forest</b> (RF) dengan test_mse(310) dan test_r2(0.74)"""